{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a88b35-7519-4363-90d2-c62c3efe9df0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e627874c-0651-4784-afd2-0fdad935eae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets\n",
    "!pip install -q git+https://github.com/huggingface/transformers\n",
    "!pip install -q bitsandbytes sentencepiece accelerate loralib\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d36c06-d675-4a75-9c3a-b558c6721f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from PIL import Image\n",
    "from transformers import IdeficsForVisionText2Text, AutoProcessor, Trainer, TrainingArguments, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a13d73-2e24-49ac-a365-60d9ee0dd3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 21 04:04:38 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:02:00.0 Off |                  N/A |\n",
      "|  0%   33C    P8             41W /  420W |       2MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3f6080-bc56-4103-9b5d-16670ab85893",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f3754ab-dd57-4860-9887-2579219a7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e504d4c-265a-4825-8c59-d012be117f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"HuggingFaceM4/idefics-9b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f350406-6c84-4cfb-aa58-4cc36ba8159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    llm_int8_skip_modules=['lm_head', 'embed_tokens']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94dbd292-a5b5-4712-8077-e86a9d3d4079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbadcc9e889d4078b95085042b562c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d622c87ba9cf4f41a3f8e555c0f098e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c082daa24f54032ada55e8694a623f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e14db5075c4a3f95541951b54574ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b918da4860274423888afe5ac5cf95b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b5e408f2f04be4a700854dd7eed0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(checkpoint, cache_dir='workspace/hf_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4fae1dad-3ba8-4c38-b258-9b92a6135d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc28be83856f408a912265801493a8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = IdeficsForVisionText2Text.from_pretrained(checkpoint, quantization_config=bnb_config, device_map='auto', cache_dir='workspace/hf_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d3e98b-14ea-47cc-b465-7cd44bded6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IdeficsForVisionText2Text(\n",
       "  (model): IdeficsModel(\n",
       "    (embed_tokens): IdeficsDecoupledEmbedding(\n",
       "      num_embeddings=32000, num_additional_embeddings=2, embedding_dim=4096, partially_freeze=False\n",
       "      (additional_embedding): Embedding(2, 4096)\n",
       "    )\n",
       "    (vision_model): IdeficsVisionTransformer(\n",
       "      (embeddings): IdeficsVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "        (position_embedding): Embedding(257, 1280)\n",
       "      )\n",
       "      (pre_layrnorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder): IdeficsVisionEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x IdeficsVisionEncoderLayer(\n",
       "            (self_attn): IdeficsVisionAttention(\n",
       "              (k_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
       "              (v_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
       "              (q_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
       "              (out_proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): IdeficsVisionMLP(\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (perceiver_resampler): IdeficsPerceiverResampler(\n",
       "      (blocks): ModuleList(\n",
       "        (0-5): 6 x ModuleList(\n",
       "          (0): IdeficsPerceiverAttention(\n",
       "            (context_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (latents_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (q_layer_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (k_layer_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (q_proj): Linear4bit(in_features=1280, out_features=1536, bias=False)\n",
       "            (k_proj): Linear4bit(in_features=1280, out_features=1536, bias=False)\n",
       "            (v_proj): Linear4bit(in_features=1280, out_features=1536, bias=False)\n",
       "            (output_proj): Linear4bit(in_features=1536, out_features=1280, bias=False)\n",
       "          )\n",
       "          (1): IdeficsMLP(\n",
       "            (ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc): Linear4bit(in_features=1280, out_features=5120, bias=False)\n",
       "            (act): ReLU()\n",
       "            (c_proj): Linear4bit(in_features=5120, out_features=1280, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x IdeficsDecoderLayer(\n",
       "        (self_attn): IdeficsAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): IdeficsEmbedding()\n",
       "        )\n",
       "        (mlp): IdeficsMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): IdeficsRMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): IdeficsRMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (gated_cross_attn_layers): ModuleList(\n",
       "      (0-7): 8 x IdeficsGatedCrossAttentionLayer(\n",
       "        (cross_attn): IdeficsAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=1280, out_features=4096, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=1280, out_features=4096, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): IdeficsEmbedding()\n",
       "          (q_layer_norm): IdeficsRMSNorm((128,), eps=1e-06)\n",
       "          (k_layer_norm): IdeficsRMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): IdeficsMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): IdeficsRMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): IdeficsRMSNorm((4096,), eps=1e-06)\n",
       "        (act_cross_attn): Tanh()\n",
       "        (act_dense): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (norm): IdeficsRMSNorm((4096,), eps=1e-06)\n",
       "  )\n",
       "  (lm_head): IdeficsDecoupledLinear(\n",
       "    in_features=4096, out_features=32000, out_additional_features=2, bias=False, partially_freeze=False\n",
       "    (additional_fc): Linear(in_features=4096, out_features=2, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a00cc7f-e6dc-447c-b014-ecfd1c2e1b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "def do_inference(model, processor, prompts, max_new_tokens=50):\n",
    "    tokenizer = processor.tokenizer\n",
    "    bad_words = [\"<image>\", \"<fake_token_around_image>\"]\n",
    "    if len(bad_words) > 0:\n",
    "        bad_words_ids = tokenizer(bad_words, add_special_tokens=False).input_ids\n",
    "    eos_token = \"</s>\"\n",
    "    eos_token_id = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "\n",
    "    inputs = processor(prompts, return_tensors='pt').to(device)\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        eos_token_id=[eos_token_id],\n",
    "        bad_words_ids=bad_words_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    print(generated_text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c1d7532-74a1-4983-9783-40e70fe22965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What's on the picture? Answer: Lucario.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://images.pokemontcg.io/pop6/2_hires.png\"\n",
    "\n",
    "prompts = [\n",
    "    url,\n",
    "    \"Question: What's on the picture? Answer:\",\n",
    "]\n",
    "\n",
    "do_inference(model, processor, prompts, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1988f931-b243-4634-9c3c-0d636fe575e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d744677b-5683-4581-92cf-0dcfc2398481",
   "metadata": {},
   "outputs": [],
   "source": [
    "##preprocessing\n",
    "def convert_to_rgb(image):\n",
    "  if image.mode == \"RGB\":\n",
    "    return image\n",
    "\n",
    "  image_rgba = image.convert(\"RGBA\")\n",
    "  background = Image.new(\"RGBA\", image_rgba.size, (255,255,255))\n",
    "  alpha_composite = Image.alpha_composite(background, image_rgba)\n",
    "  alpha_composite = alpha_composite.convert(\"RGB\")\n",
    "  return alpha_composite\n",
    "\n",
    "def ds_transforms(example_batch):\n",
    "  image_size = processor.image_processor.image_size\n",
    "  image_mean = processor.image_processor.image_mean\n",
    "  image_std = processor.image_processor.image_std\n",
    "\n",
    "  image_transform = transforms.Compose([\n",
    "      convert_to_rgb,\n",
    "      transforms.RandomResizedCrop((image_size, image_size), scale=(0.9, 1.0), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=image_mean, std=image_std)\n",
    "  ])\n",
    "\n",
    "  prompts = []\n",
    "  for i in range(len(example_batch['caption'])):\n",
    "    caption = example_batch['caption'][i].split(\".\")[0]\n",
    "    prompts.append(\n",
    "        [\n",
    "            example_batch['image_url'][i],\n",
    "            f\"Question: What's on the picture? Answer: This is {example_batch['name']}. {caption}\",\n",
    "        ],\n",
    "    )\n",
    "  inputs = processor(prompts, transform=image_transform, return_tensors=\"pt\").to(device)\n",
    "  inputs[\"labels\"] = inputs[\"input_ids\"]\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13da437d-5681-44b0-a42b-2722400aa779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560f7a9717eb49c984afa956ab7b4a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad9c8de7c4e4087a62b14eba9211a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv:   0%|          | 0.00/9.28M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2f811c33f54c07abc4452742ca4aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/13139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load and prepare the data for finetuning\n",
    "\n",
    "ds = load_dataset('TheFusion21/PokemonCards', cache_dir='workspace/hf_cache')\n",
    "ds = ds['train'].train_test_split(test_size=0.002, seed=42)\n",
    "train_ds = ds['train']\n",
    "eval_ds = ds['test']\n",
    "train_ds.set_transform(ds_transforms)\n",
    "eval_ds.set_transform(ds_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "788ba365-37a9-4a9f-bc67-20450bcdf1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = checkpoint.split('/')[1]\n",
    "config = LoraConfig(\n",
    "    r = 16, # if model is small, rank should be higher\n",
    "    lora_alpha = 32,\n",
    "    target_modules = ['q_proj', 'k_proj', 'v_proj'],\n",
    "    lora_dropout = 0.05,\n",
    "    bias = 'none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9f50a7a-192b-436a-9b08-87105f15a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a259bb3-83b0-45e2-8df5-525a32fb656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 19,750,912 || all params: 8,949,430,544 || trainable%: 0.2207\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ebf9f55-40d0-417f-be77-a6dab8bc18fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = f'{model_name}-PokemonCards',\n",
    "    learning_rate = 2e-4,\n",
    "    fp16 = True,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    dataloader_pin_memory=False,\n",
    "    save_total_limit=3,\n",
    "    evaluation_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    eval_steps=25,\n",
    "    save_steps=50,\n",
    "    max_steps=50,\n",
    "    logging_steps=10,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    label_names=['labels'],\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='none',\n",
    "    optim='paged_adamw_8bit'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b432561a-ea93-48b8-914e-568d68db3dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7df90d2-cc50-485e-94a4-6537cab356af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You may have used the wrong order for inputs. `images` should be passed before `text`. The `images` and `text` inputs will be swapped. This behavior will be deprecated in transformers v4.47.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 10:18, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>8.062600</td>\n",
       "      <td>0.803174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.671900</td>\n",
       "      <td>0.726063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08395dac9bd424ba4e7bf97cc97f09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=50, training_loss=9.168774032592774, metrics={'train_runtime': 632.9308, 'train_samples_per_second': 1.264, 'train_steps_per_second': 0.079, 'total_flos': 3796581474282816.0, 'train_loss': 9.168774032592774, 'epoch': 0.06101281269066504})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d3767b-a749-4542-823e-134328ce0176",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99a34c59-74e3-4cdb-8f75-654df188adc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What's on the picture? Answer: This is ['Lucario', 'Scyther']. A Stage 1 Pokemon Card of type Darkness with the title Lucario and 90 HP of rarity Rare evolved from Pikachu from the set Neo Genesis and the flavor text: It can use its tail to attack enemies from behind, and it can also use its tail to block attacks from the front. It is said that it can use its tail to attack enemies from behind,\n"
     ]
    }
   ],
   "source": [
    "url = \"https://images.pokemontcg.io/pop6/2_hires.png\"\n",
    "\n",
    "prompts = [\n",
    "    url,\n",
    "    \"Question: What's on the picture? Answer:\",\n",
    "]\n",
    "\n",
    "do_inference(model, processor, prompts, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc17046c-bf40-421b-a3bd-24270e301aee",
   "metadata": {},
   "source": [
    "# Push To Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96ccdcbd-99e7-4e89-bce1-def2cf417caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Hugging Face token:  ········\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import getpass\n",
    "\n",
    "# Prompt for token input\n",
    "token = getpass.getpass(\"Enter your Hugging Face token: \")\n",
    "\n",
    "# Log in with the provided token\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1e2e658-54f9-4d34-87d8-50267919ee5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64caae5f5d541eb94a6eb71f15d2022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/79.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/gauravparajuli/idefics-9b-PokemonCards/commit/117f61d6d37deda39add603c683f16fbc6336a78', commit_message='Upload model', commit_description='', oid='117f61d6d37deda39add603c683f16fbc6336a78', pr_url=None, repo_url=RepoUrl('https://huggingface.co/gauravparajuli/idefics-9b-PokemonCards', endpoint='https://huggingface.co', repo_type='model', repo_id='gauravparajuli/idefics-9b-PokemonCards'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(f\"{model_name}-PokemonCards\", private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c344f5-2cfd-4bc5-b636-ecc6977cd855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
